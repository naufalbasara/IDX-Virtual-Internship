# -*- coding: utf-8 -*-
"""0 ETL.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10YtqAMEzoo333KgYDibjlxHuqGnRB67Y

## Libraries
"""

!pip install scikit-learn

import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
import tensorflow as tf
import seaborn as sns

"""## Data Understanding"""

base_path = '/content/drive/MyDrive/Internship/IDX Partners'
data_path = os.path.join(base_path, 'Dataset')

df = pd.read_csv(os.path.join(data_path, 'loan_data_2007_2014.csv'))
df.info()

df.iloc[:, :10].describe()

df.iloc[:, 10:40].describe()

df.iloc[:, 40:].describe()

df

"""## Preprocessing

### Drop Duplicates
"""

df.drop_duplicates(inplace=True)

"""### Drop Null Values"""

df.dropna(axis=0, how='all' ,inplace=True) # Drop all null rows in dataframe
df.dropna(axis=1, how='all' ,inplace=True) # Drop all null columns in dataframe
df.drop(columns='Unnamed: 0', axis=1, inplace=True)

df.info()

df['loan_status'].unique()

df['loan_status'].value_counts()

"""### Fill NAs"""

print(f"total unique employment title: {len(df['emp_title'].unique())}")

df['emp_title'].fillna(value='unemployment', inplace=True)

df['emp_length'].unique()

df['emp_length']

df['emp_length'] = np.where(df['annual_inc'].isna(), '< 1 year', df['emp_length'])
df['emp_length'] = np.where((df['annual_inc'].isna() | df['emp_length'].isna()), '< 1 year', df['emp_length'])
df['desc'] = np.where(df['desc'].isna(), df['purpose'], df['desc'])

df = df[~df['annual_inc'].isna()]
df = df[~df['earliest_cr_line'].isna()]
df['title'] = np.where(df['title'].isna(), df['purpose'], df['title'])

df['application_type'].value_counts()

# Drop the application type since its only 1 value
df.drop(['application_type'], axis=1, inplace=True)

df[df['next_pymnt_d'].isna()][['loan_status']].value_counts()

df[df['next_pymnt_d'].notna()][['loan_status']].value_counts()

df.drop(['mths_since_last_major_derog'], axis=1, inplace=True)

# drop the column of next payment date because all of the loan status where the next payment date is null is already done
df.drop(['next_pymnt_d', 'last_pymnt_d'], axis=1, inplace=True)

# Change datetime data type
df['issue_d'] = pd.to_datetime(df['issue_d'], format='%b-%y')
df['issue_d']

# Fill null of revolving utilization with 0
df['revol_util'].fillna(value=0, inplace=True)

df[df['mths_since_last_delinq'].isna()]['loan_status'].value_counts()

# Fill nulls of mths_since_last_delinq with 0 with assumption that the credit member didnt do deliquency
df['mths_since_last_delinq'].fillna(value=0, inplace=True)


# After a serious delinquency, a creditor may take legal action against you,
# which may become a public record and, in some cases, appear on your credit report.

# Fill nulls of mths_since_last_record with 0 with assumption that the creditor may not take legal action against the credit member
df['mths_since_last_record'].fillna(value=0, inplace=True)

df['collections_12_mths_ex_med'].fillna(value=0, inplace=True)

df.drop(['last_credit_pull_d'], axis=1, inplace=True)

df['tot_coll_amt'] = np.where(df['tot_coll_amt'].isna(), 0, df['tot_coll_amt'])

# Fill null values in tot_cur_bal with balance from revolving account in assumption that the borrower only have revolving account
df['tot_cur_bal'] = np.where(df['tot_cur_bal'].isna(), df['revol_bal'], df['tot_cur_bal'])

df[(df['sub_grade'] == 'B2')][['grade', 'sub_grade','annual_inc', 'revol_bal', 'tot_cur_bal', 'revol_util', 'total_rev_hi_lim']]

a_mean = df[(df['grade'] == 'A')]['total_rev_hi_lim'].mean()
b_mean = df[(df['grade'] == 'B')]['total_rev_hi_lim'].mean()
c_mean = df[(df['grade'] == 'C')]['total_rev_hi_lim'].mean()
d_mean = df[(df['grade'] == 'D')]['total_rev_hi_lim'].mean()
e_mean = df[(df['grade'] == 'E')]['total_rev_hi_lim'].mean()
f_mean = df[(df['grade'] == 'F')]['total_rev_hi_lim'].mean()
g_mean = df[(df['grade'] == 'G')]['total_rev_hi_lim'].mean()

print(f"a mean: {a_mean}")
print(f"b mean: {b_mean}")
print(f"c mean: {c_mean}")
print(f"d mean: {d_mean}")
print(f"e mean: {e_mean}")
print(f"f mean: {f_mean}")
print(f"g mean: {g_mean}")

df.loc[(df['grade']=='A') & (df['total_rev_hi_lim'].isna()), 'total_rev_hi_lim'] = a_mean
df.loc[(df['grade']=='B') & (df['total_rev_hi_lim'].isna()), 'total_rev_hi_lim'] = b_mean
df.loc[(df['grade']=='C') & (df['total_rev_hi_lim'].isna()), 'total_rev_hi_lim'] = c_mean
df.loc[(df['grade']=='D') & (df['total_rev_hi_lim'].isna()), 'total_rev_hi_lim'] = d_mean
df.loc[(df['grade']=='E') & (df['total_rev_hi_lim'].isna()), 'total_rev_hi_lim'] = e_mean
df.loc[(df['grade']=='F') & (df['total_rev_hi_lim'].isna()), 'total_rev_hi_lim'] = f_mean
df.loc[(df['grade']=='G') & (df['total_rev_hi_lim'].isna()), 'total_rev_hi_lim'] = g_mean

"""### Check Outliers"""

df_copy = df.copy()

for col in df_copy.columns:
  if df_copy[col].dtypes not in ['object', 'O']:
    try:
      df_copy.plot(kind='scatter', x='id', y=col)
    except:
      print(f'column {col} can\'t be plotted')
  else:
    continue

col = 'revol_util'

Q1 = np.percentile(df_copy[col], 25, method='midpoint')
Q3 = np.percentile(df_copy[col], 75, method='midpoint')
IQR = Q3 - Q1
lower = Q1 -1.5*IQR
upper = Q3 +1.5*IQR

    # Create arrays of Boolean values indicating the outlier rows
upper_array = np.where(df_copy[col]>=upper)[0]
lower_array = np.where(df_copy[col]<=lower)[0]
print(f'number of outlier in column {col} are {len(upper_array) + len(lower_array)}')
    # Removing the outliers
try:
  plt.figure()
  # df_copy.drop(index=upper_array, axis=0, inplace=True)
  # df_copy.drop(index=lower_array, axis=0, inplace=True)
  df_copy.boxplot([col])
except Exception as e:
  print(f'column {col} can\'t be plotted')

df_copy = df.copy()

for col in df_copy.columns:
  if df_copy[col].dtypes not in ['object', 'O']:
    Q1 = np.percentile(df_copy[col], 25, method='midpoint')
    Q3 = np.percentile(df_copy[col], 75, method='midpoint')
    IQR = Q3 - Q1
    upper = Q3 +1.5*IQR
    lower = Q1 -1.5*IQR

    # Create arrays of Boolean values indicating the outlier rows
    upper_array = np.where(df_copy[col]>=upper)[0]
    lower_array = np.where(df_copy[col]<=lower)[0]
    print(f'number of outlier in column {col} are {len(upper_array) + len(lower_array)}')

    # Removing the outliers
    try:
      plt.figure()
      df_copy.boxplot([col])

    except Exception as e:
      print(f'column {col} can\'t be plotted')
  else:
    continue

"""### Save cleaned dataset"""

df.info()

df.to_csv(os.path.join(data_path, 'cleaned-dataset-v1.csv'))

