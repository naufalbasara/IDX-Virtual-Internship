# -*- coding: utf-8 -*-
"""1 EDA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RfqAGyhd0kRFRf5bEVjxJfU57-RXpzmV
"""

import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
import tensorflow as tf
import seaborn as sns

base_path = '/content/drive/MyDrive/Internship/IDX Partners'
data_path = os.path.join(base_path, 'Dataset')

"""## Understanding Data"""

df = pd.read_csv(os.path.join(data_path, 'cleaned-dataset-v1.csv'))
df.drop('Unnamed: 0', axis=1, inplace=True)
df.info()

df['purpose'].unique()

def addlabels(x,y):
    for i in range(len(x)):
        plt.text(i, y[i]//2, y[i], ha = 'center')

# Customer Segmentation 1
df['purpose'].value_counts().plot(kind='bar')
plt.title('Member Loan Purposes Distribution')
addlabels(df['purpose'].unique(), df['purpose'].value_counts())

# Customer Segmentation 2
df['emp_title'].value_counts()[:20].plot(kind='pie')

df['loan_status'].value_counts().plot(kind='bar')
plt.title('Percentage of member\'s loan status')
addlabels(df['loan_status'].unique(), df['loan_status'].value_counts())
plt.show()

y = df['loan_status'].value_counts()
labels = df['loan_status'].unique()
fig, ax = plt.subplots()
ax.pie(y, autopct='%1.1f%%')
plt.title('Percentage of member\'s loan status')
plt.legend(labels=labels, loc='center left', bbox_to_anchor=(1, .5), fontsize=8)
plt.show()

"""## Feature Engineering

### Feature Manipulation
"""

df.info()

# Drop the column that were categorical with large variety of value

# Drop the column that refer to identifier of the loan member
df.drop(['id', 'member_id', 'url', 'desc', 'title', 'addr_state', 'zip_code'], axis=1, inplace=True)
df.drop(['issue_d', 'sub_grade', 'purpose', 'earliest_cr_line'], axis=1, inplace=True)

df['term'] = df['term'].apply(lambda x: x.strip().split()[0]).astype('int')

df['emp_length'].unique()
length_to_year = {
    '< 1 year': 0,
    '1 year': 1,
    '2 years': 2,
    '3 years': 3,
    '4 years': 4,
    '5 years': 5,
    '6 years': 6,
    '7 years': 7,
    '8 years': 8,
    '9 years': 9,
    '10+ years': 10,
}

df['emp_length'] = df['emp_length'].apply(lambda x: length_to_year[x]).astype('int')
df['emp_length']

df['grade'].unique()
encode_grade = {
    'A': 0,
    'B': 1,
    'C': 2,
    'D': 3,
    'E': 4,
    'F': 5,
    'G': 6,
}

decode_grade = {
    0: 'A',
    1: 'B',
    2: 'C',
    3: 'D',
    4: 'E',
    5: 'F',
    6: 'G',
}

df['grade'] = df['grade'].apply(lambda x: encode_grade[x]).astype('int')
df['grade']

df['verification_status'].unique()

encode_verification_status = {
    'Not Verified': 0,
    'Source Verified': 1,
    'Verified': 2,
}

decode_verification_status = {
    0: 'Not Verified',
    1: 'Source Verified',
    2: 'Verified',
}

df['verification_status'] = df['verification_status'].apply(lambda x: encode_verification_status[x]).astype('int')
df['verification_status']

df['pymnt_plan'].unique()

encode_pymnt_plan = {
    'y': 1,
    'n': 0
}

decode_pymnt_plan = {
    1: 'y',
    0: 'n'
}

df['pymnt_plan'] = df['pymnt_plan'].apply(lambda x: encode_pymnt_plan[x]).astype('int')

df['initial_list_status'].unique()

encode_initial_list_status = {
    'w': 1,
    'f': 0
}

df['initial_list_status'] = df['initial_list_status'].apply(lambda x: encode_initial_list_status[x]).astype('int')

df['home_ownership'].unique()

encode_home_ownership = {
    'RENT': 0,
    'OWN': 1,
    'MORTGAGE': 2,
    'OTHER': 3,
    'NONE': 4,
    'ANY': 5,
}

decode_home_ownership = {
    0: 'RENT',
    1: 'OWN',
    2: 'MORTGAGE',
    3: 'OTHER',
    4: 'NONE',
    5: 'ANY',
}

df['home_ownership'] = df['home_ownership'].apply(lambda x: encode_home_ownership[x]).astype('int')
df['home_ownership']

# change the value of emp_title column due to large variety of value
conditions = [
    df['emp_title'] == 'unemployment',
    df['emp_title'] != 'unemployment',
]
outputs = [
    0, 1
]

df['employed'] = np.select(conditions, outputs)
df.drop(['emp_title'], axis=1, inplace=True)

decode_employed = {
    1: 'employed',
    0: 'unemployed'
}

# Member loan risk assessment distribution
df['employed'].apply(lambda x: decode_employed[x]).value_counts().plot(kind='bar', color=['C0', 'C1'])
plt.title('Borrowers Employment Distribution')
addlabels(df['employed'].unique(), sorted(df['employed'].value_counts(), reverse=True))

# find the total number of loan status of employee with each length of working experience

df_group = df[['employed', 'risk_assessment']]
df_group['employed'] = df_group['employed'].apply(lambda x: decode_employed[x])

df_group_total = df_group.groupby('employed').count()
df_group_pos = df_group.groupby('employed').sum()
df_group_neg = df_group_total - df_group_pos

df_copy = pd.DataFrame({'good': (np.array(df_group_pos).reshape(2,)),
                   'risky': (np.array(df_group_neg).reshape(2,))}, index=df_group_total.index).sort_values(by=['good'])

ax = df_copy.plot.bar(rot=0, figsize=(10, 5))
addlabels(df['employed'].unique(), sorted(df['employed'].value_counts(), reverse=False))

df['annual_inc'].describe()

df[df['annual_inc'] == df['annual_inc'].max()]['annual_inc']

# Determine the good and risky loan status
conditions = [
    df['annual_inc'] <= 1e+4,
    df['annual_inc'] <= 1e+5,
    df['annual_inc'] <= 1e+6,
    df['annual_inc'] <= 1e+7,

]
outputs = [
    '> 1,000',
    '> 10,000',
    '> 100,000',
    '> 1,000,000',
]

df['annual_income'] = np.select(conditions, outputs)

# df['home_ownership'].value_counts().plot(kind='bar')

df_group = df[['annual_income', 'risk_assessment']]

df_group_total = df_group.groupby('annual_income').count()
df_group_pos = df_group.groupby('annual_income').sum()
df_group_neg = df_group_total - df_group_pos

df_copy = pd.DataFrame({'good': (np.array(df_group_pos).reshape(4,)),
                   'risky': (np.array(df_group_neg).reshape(4,))}, index=df_group_total.index).sort_values(by=['good'])

ax = df_copy.plot.bar(rot=0, figsize=(10, 5))
addlabels(df['annual_income'].unique(), sorted(df['annual_income'].value_counts(), reverse=False))
plt.title('Borrower\'s Annual Income')

# Determine the good and risky loan status
conditions = [
    df['loan_status'] == 'Fully Paid',
    df['loan_status'] == 'Charged Off',
    df['loan_status'] == 'Current',
    df['loan_status'] == 'Default',
    df['loan_status'] == 'In Grace Period',
    df['loan_status'] == 'Late (31-120 days)',
    df['loan_status'] == 'Late (16-30 days)',
    df['loan_status'] == 'Does not meet the credit policy. Status: Fully Paid',
    df['loan_status'] == 'Does not meet the credit policy. Status: Charged Off',
]
outputs = [
    1, 0, 1, 0, 0, 0, 0, 1, 0
]

df['risk_assessment'] = np.select(conditions, outputs)
df.drop(['loan_status'], axis=1, inplace=True)

# Member loan risk assessment distribution
df['risk_assessment'].value_counts().plot(kind='bar', color=['C0', 'C3'])
plt.title('Member Loan Risk Assessment Distribution')
addlabels(df['risk_assessment'].unique(), sorted(df['risk_assessment'].value_counts(), reverse=True))

sns.pairplot(df, vars=['loan_amnt', 'annual_inc', 'recoveries', 'tot_cur_bal'], hue='risk_assessment')
plt.show()

# df['home_ownership'].value_counts().plot(kind='bar')

df_group = df[['home_ownership', 'risk_assessment']]
df_group['home_ownership'] = df_group['home_ownership'].apply(lambda x: decode_home_ownership[x])

df_group_total = df_group.groupby('home_ownership').count()
df_group_pos = df_group.groupby('home_ownership').sum()
df_group_neg = df_group_total - df_group_pos

df_copy = pd.DataFrame({'good': (np.array(df_group_pos).reshape(6,)),
                   'risky': (np.array(df_group_neg).reshape(6,))}, index=df_group_total.index).sort_values(by=['good'])

ax = df_copy.plot.bar(rot=0, figsize=(10, 5))
addlabels(df['home_ownership'].unique(), sorted(df['home_ownership'].value_counts(), reverse=False))

# find the total number of loan status of employee with each length of working experience

df_group = df[['emp_length', 'risk_assessment']]

df_group_total = df_group.groupby('emp_length').count()
df_group_pos = df_group.groupby('emp_length').sum()
df_group_neg = df_group_total - df_group_pos

df_copy = pd.DataFrame({'good': (np.array(df_group_pos).reshape(11,)),
                   'risky': (np.array(df_group_neg).reshape(11,))}, index=df_group_total.index).sort_values(by=['good'])

ax = df_copy.plot.bar(rot=0, figsize=(10, 5))

df[df['risk_assessment'] == 1]['grade'].apply(lambda x: decode_grade[x]).value_counts().plot(kind='bar')
plt.title('Good Credit Grade Distribution')
plt.xlabel('Credit Grade')
plt.ylabel('# of risky credit members')
plt.show()

df[df['risk_assessment'] == 0]['grade'].apply(lambda x: decode_grade[x]).value_counts().plot(kind='bar', color='red')
plt.title('Risky Credit Grade Distribution')
plt.xlabel('Credit Grade')
plt.ylabel('# of risky credit members')
plt.show()

# find the total number of loan status of employee with each length of working experience

df_group = df[['grade', 'risk_assessment']]
df_group['grade'] = df_group['grade'].apply(lambda x: decode_grade[x])

df_group_total = df_group.groupby('grade').count()
df_group_pos = df_group.groupby('grade').sum()
df_group_neg = df_group_total - df_group_pos

df_copy = pd.DataFrame({'good': (np.array(df_group_pos).reshape(7,)),
                   'risky': (np.array(df_group_neg).reshape(7,))}, index=df_group_total.index).sort_values(by=['good'])

ax = df_copy.plot.bar(rot=0, figsize=(10, 5))
addlabels(df['grade'].unique(), sorted(df['grade'].value_counts(), reverse=False))

df_group = df[['verification_status', 'risk_assessment']]
df_group['verification_status'] = df_group['verification_status'].apply(lambda x: decode_verification_status[x])

df_group_total = df_group.groupby('verification_status').count()
df_group_pos = df_group.groupby('verification_status').sum()
df_group_neg = df_group_total - df_group_pos

df_copy = pd.DataFrame({'good': (np.array(df_group_pos).reshape(3,)),
                   'risky': (np.array(df_group_neg).reshape(3,))}, index=df_group_total.index).sort_values(by=['good'])

ax = df_copy.plot.bar(rot=0, figsize=(10, 5))

sns.scatterplot(x="installment",
                    y="tot_cur_bal",
                    data=df,
                    hue='risk_assessment'
                )

sns.scatterplot(x="recoveries",
                    y="tot_cur_bal",
                    data=df,
                    hue='risk_assessment'
                )

sns.scatterplot(x="recoveries",
                    y="annual_inc",
                    data=df,
                    hue='risk_assessment'
                )

sns.scatterplot(x="tot_cur_bal",
                    y="annual_inc",
                    data=df,
                    hue='risk_assessment'
                )

sns.scatterplot(x="installment",
                    y="annual_inc",
                    data=df,
                    hue='risk_assessment'
                )

sns.heatmap(df.corr())

df.info()

"""### Feature Importance"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split

X = df.iloc[:, :-1]
y = df.iloc[:, -1]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)

# define the model
model = RandomForestRegressor()
# fit the model
model.fit(X_train, y_train)
# get importance
importance = model.feature_importances_
# summarize feature importance
for i,v in enumerate(importance):
 print(f'Feature: {i} {df.columns[i]}, Score: {v}')
# plot feature importance
plt.bar([x for x in range(len(importance))], importance)
plt.show()

from sklearn.tree import DecisionTreeRegressor
from matplotlib import pyplot

X = df.iloc[:, :-1]
y = df.iloc[:, -1]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)

# define the model
model = DecisionTreeRegressor()
# fit the model
model.fit(X_train, y_train)
# get importance
importance = model.feature_importances_
# summarize feature importance
for i,v in enumerate(importance):
 print(f'Feature: {i} {df.columns[i]}, Score: {v}')
# plot feature importance
pyplot.bar([x for x in range(len(importance))], importance)
pyplot.show()

df.to_csv(os.path.join(data_path, 'cleaned-model-v1.csv'))

